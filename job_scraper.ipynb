{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00487a14",
   "metadata": {},
   "source": [
    "# Simple Job scraping file\n",
    "\n",
    "*Scrape job details from indeed website*\n",
    "\n",
    "### Github: https://github.com/raydiwill/Job-Scraper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920e7d0",
   "metadata": {},
   "source": [
    "## Install prerequisite packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422ad394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prerequisite packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41293bef",
   "metadata": {},
   "source": [
    "## Create soup object from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35c9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to creat the soup object from the url.\n",
    "def extract_page(page):\n",
    "    # The url may vary, special note at page argument \n",
    "    url = f'https://vn.indeed.com/Vi%E1%BB%87c-l%C3%A0m?q=data%20analyst&l=H%C3%A0%20N%E1%BB%99i&start={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f0281",
   "metadata": {},
   "source": [
    "## Extract desirable information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4238b4dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to scrape data from html texts.\n",
    "def extract_content(soup):\n",
    "    # Each job is wrapped inside an a tag, within the tag contains job details\n",
    "    job_elements = soup.find_all(\"a\", class_=\"tapItem\")\n",
    "    \n",
    "    # Loop through each object to find job details\n",
    "    for job_element in job_elements:\n",
    "        title = job_element.find(\"h2\", class_=\"jobTitle\")\n",
    "        \n",
    "        # Some jobs from indeed.com can have a label wrapped in sub-tag indicating if they're new, this condition check if \n",
    "        # there are more tags than the others. Else, return the job title\n",
    "        if (len(title.findChildren()) > 1):\n",
    "            title = title.find_next(\"span\").find_next(\"span\").text\n",
    "        else: \n",
    "            title = title.text\n",
    "        company = job_element.find(\"span\", class_=\"companyName\")\n",
    "        location = job_element.find(\"div\", class_=\"companyLocation\")\n",
    "        description = job_element.find(\"div\", class_=\"job-snippet\")\n",
    "        salary = job_element.find(\"div\", class_=\"salary-snippet\")\n",
    "        \n",
    "        # Some jobs may post the salary detail, others may not\n",
    "        if salary:\n",
    "            salary = salary.text.strip()\n",
    "        else:\n",
    "            salary = '' \n",
    "        post_date = job_element.find('span', 'date').text\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Create a tuple to store the data\n",
    "        record = (title, company.text, location.text, post_date, today, salary, description.text.strip().replace('\\n', ' '))\n",
    "        records.append(record)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554a297",
   "metadata": {},
   "source": [
    "## Scrape data in each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028cf8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job details from page 1\n",
      "Scraping job details from page 2\n",
      "Scraping job details from page 3\n",
      "Scraping job details from page 4\n",
      "Scraping job details from page 5\n",
      "Scraping job details from page 6\n",
      "Process finished! Create a dataframe to store the results\n"
     ]
    }
   ],
   "source": [
    "# Init a list to store all job data\n",
    "records = []\n",
    "\n",
    "# Loop through each page until there is no more additional job pages\n",
    "for i in range(0, 60, 10):\n",
    "    print(f'Scraping job details from page {round(i/10+1)}')\n",
    "    page = extract_page(0)\n",
    "    extract_content(page)\n",
    "    \n",
    "print(\"Process finished! Create a dataframe to store the results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c035c5",
   "metadata": {},
   "source": [
    "## Create dataframe to store results and export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e40c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            JobTitle  \\\n",
      "0                       Data Analyst   \n",
      "1  Fresh Business Analyst IT Project   \n",
      "2                  Data Analyst (HN)   \n",
      "3                       DATA ANALYST   \n",
      "4                       Data Analyst   \n",
      "\n",
      "                                             Company Location  \\\n",
      "0  Công Ty Cổ Phần Truyền Thông Và Giải Trí HG Media   Hà Nội   \n",
      "1                      Công TY TNHH Tripath Việt Nam   Hà Nội   \n",
      "2                          Viettel Cyberspace Center   Hà Nội   \n",
      "3                                          VMG Media   Hà Nội   \n",
      "4                              Chứng khoán Kỹ Thương   Hà Nội   \n",
      "\n",
      "             DatePosted DateExtracted                    Salary  \\\n",
      "0    Posted1 ngày trước    2022-01-21  15.000.000 VNĐ một tháng   \n",
      "1   Posted14 ngày trước    2022-01-21  10.000.000 VNĐ một tháng   \n",
      "2  Posted30+ ngày trước    2022-01-21                             \n",
      "3   Posted10 ngày trước    2022-01-21                             \n",
      "4  Posted30+ ngày trước    2022-01-21                             \n",
      "\n",
      "                                         Description  \n",
      "0  Các chế độ du lịch, trợ cấp gửi xe... theo c...  \n",
      "1  Tham gia thực hiện công việc ở vị trí BA cho c...  \n",
      "2  Phối hợp với Data Scientist để trích xuất các ...  \n",
      "3  Có kinh nghiệm, am hiểu về Big Data, Data-Ware...  \n",
      "4  Develop and implement databases, data collecti...  \n"
     ]
    }
   ],
   "source": [
    "# Convert list into data frame for easier to view and write to csv file\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Add meaningful names to the data frame\n",
    "df.columns = ['JobTitle', 'Company', 'Location', 'DatePosted', 'DateExtracted', 'Salary', 'Description']\n",
    "#print(df.head())\n",
    "\n",
    "# Write to csv file \n",
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d782fe",
   "metadata": {},
   "source": [
    "## The entire code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8aa2583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job details from page 1\n",
      "Scraping job details from page 2\n",
      "Scraping job details from page 3\n",
      "Scraping job details from page 4\n",
      "Scraping job details from page 5\n",
      "Scraping job details from page 6\n",
      "Process finished! Create a dataframe to store the results\n",
      "                            JobTitle  \\\n",
      "0                       Data Analyst   \n",
      "1  Fresh Business Analyst IT Project   \n",
      "2                  Data Analyst (HN)   \n",
      "3                       DATA ANALYST   \n",
      "4                       Data Analyst   \n",
      "\n",
      "                                             Company Location  \\\n",
      "0  Công Ty Cổ Phần Truyền Thông Và Giải Trí HG Media   Hà Nội   \n",
      "1                      Công TY TNHH Tripath Việt Nam   Hà Nội   \n",
      "2                          Viettel Cyberspace Center   Hà Nội   \n",
      "3                                          VMG Media   Hà Nội   \n",
      "4                              Chứng khoán Kỹ Thương   Hà Nội   \n",
      "\n",
      "             DatePosted DateExtracted                    Salary  \\\n",
      "0    Posted1 ngày trước    2022-01-21  15.000.000 VNĐ một tháng   \n",
      "1   Posted14 ngày trước    2022-01-21  10.000.000 VNĐ một tháng   \n",
      "2  Posted30+ ngày trước    2022-01-21                             \n",
      "3   Posted10 ngày trước    2022-01-21                             \n",
      "4  Posted30+ ngày trước    2022-01-21                             \n",
      "\n",
      "                                         Description  \n",
      "0  Các chế độ du lịch, trợ cấp gửi xe... theo c...  \n",
      "1  Tham gia thực hiện công việc ở vị trí BA cho c...  \n",
      "2  Phối hợp với Data Scientist để trích xuất các ...  \n",
      "3  Có kinh nghiệm, am hiểu về Big Data, Data-Ware...  \n",
      "4  Develop and implement databases, data collecti...  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def extract_page(page):\n",
    "    url = f'https://vn.indeed.com/Vi%E1%BB%87c-l%C3%A0m?q=data%20analyst&l=H%C3%A0%20N%E1%BB%99i&start={page}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def extract_content(soup):\n",
    "    job_elements = soup.find_all(\"a\", class_=\"tapItem\")\n",
    "    for job_element in job_elements:\n",
    "        title = job_element.find(\"h2\", class_=\"jobTitle\")\n",
    "        if (len(title.findChildren()) > 1):\n",
    "            title = title.find_next(\"span\").find_next(\"span\").text\n",
    "        else: \n",
    "            title = title.text\n",
    "        company = job_element.find(\"span\", class_=\"companyName\")\n",
    "        location = job_element.find(\"div\", class_=\"companyLocation\")\n",
    "        description = job_element.find(\"div\", class_=\"job-snippet\")\n",
    "        salary = job_element.find(\"div\", class_=\"salary-snippet\")\n",
    "        if salary:\n",
    "            salary = salary.text.strip()\n",
    "        else:\n",
    "            salary = '' \n",
    "        post_date = job_element.find('span', 'date').text\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        record = (title, company.text, location.text, post_date, today, salary, description.text.strip().replace('\\n', ' '))\n",
    "        records.append(record)\n",
    "    return \n",
    "\n",
    "records = []\n",
    "for i in range(0, 60, 10):\n",
    "    print(f'Scraping job details from page {round(i/10+1)}')\n",
    "    page = extract_page(0)\n",
    "    extract_content(page)\n",
    "    \n",
    "print(\"Process finished! Create a dataframe to store the results\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.columns = ['JobTitle', 'Company', 'Location', 'DatePosted', 'DateExtracted', 'Salary', 'Description']\n",
    "print(df.head())\n",
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e55e7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
